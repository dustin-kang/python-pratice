# Sparkë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.

## Introduce Spark

<figure><img src="../.gitbook/assets/image (5) (1) (1) (1) (1).png" alt=""><figcaption><p>Spark Component</p></figcaption></figure>

SparkëŠ” <mark style="color:orange;">**ëŒ€ëŸ‰ì˜ ë°ì´í„°(Batch Data)ë¥¼ ìª¼ê°œ ë™ì‹œì— ì²˜ë¦¬**</mark>í•  ìˆ˜ ìˆëŠ” ë¹…ë°ì´í„° ì²˜ë¦¬ ì—”ì§„ì…ë‹ˆë‹¤. ì´ì „ì—ëŠ” Hadoopì„ ì‚¬ìš©í–ˆìœ¼ë‚˜ ì†ë„ë©´ì—ì„œ ì›Œë‚™ Sparkê°€ ë¹ ë¥´ê¸° ë•Œë¬¸ì— Sparkë¥¼ ë§ì´ ì‚¬ìš©í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

> í•˜ë‘¡(Hadoop)ê³¼ ê°€ì¥ í° ì°¨ì´ì ìœ¼ë¡œëŠ” ë””ìŠ¤í¬ì—ì„œ ì½ê³  ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì´ ì•„ë‹Œ **ë©”ëª¨ë¦¬ ì•ˆì—ì„œ ë°ì´í„°ë¥¼ ì²˜ë¦¬**í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤.&#x20;

> #### ğŸ’¡ ê·¸ë ‡ë‹¤ë©´ Pandas ë³´ë‹¤ ì†ë„ê°€ ë¹ ë¥¸ê°€?
>
> SparkëŠ” í™•ì¥ì„±ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆê¸° ë•Œë¬¸ì— Pandas ì†ë„ë³´ë‹¤ëŠ” ëŠë¦°í¸ì´ë‹¤. ê·¸ëŸ¬ë‚˜ íŒŒì¼ í¬ê¸°ê°€ ì¦ê°€í•  ìˆ˜ë¡ Pandasì˜ ì†ë„ëŠ” ëŠë ¤ì§€ê³  SparkëŠ” ìœ ì§€ëœë‹¤. [ì°¸ê³ ](https://databricks.com/blog/2018/05/03/benchmarking-apache-spark-on-a-single-node-machine.html)

## Structure

<figure><img src="../.gitbook/assets/image (2) (1) (1) (1).png" alt=""><figcaption><p>Spark Structure</p></figcaption></figure>

ìœ„ êµ¬ì¡°ë¥¼ ìì„¸íˆë³´ë©´,&#x20;

1. Driver Program(Python)ì´ Cluster Managerì—ê²Œ ì‘ì—… ì‹ í˜¸ë¥¼ ë³´ëƒ…ë‹ˆë‹¤.
2. Clutter ManagerëŠ” ì‘ì—…ì„ WorkerNodeì—ê²Œ ë¶„ë°°ë¥¼ í•©ë‹ˆë‹¤.
3. ê·¸ë ‡ë‹¤ë©´ ì‹¤ì§ˆì ìœ¼ë¡œ Executorê°€ ì—°ì‚°ì„ í•˜ê³  ë‹¤ì‹œ Driver Programì—ê²Œ ì „ë‹¬ í•©ë‹ˆë‹¤. ( 1 CPU : 1 Worker Node)

| ë“œë¼ì´ë²„ í”„ë¡œê·¸ë¨           | í´ëŸ¬ìŠ¤í„° ë§¤ë‹ˆì €               | ì›Œì»¤ ë…¸ë“œ                   |
| ------------------- | ---------------------- | ----------------------- |
| ì‘ì—…ì„ ìƒì‚°í•´ë‚´ëŠ” ì—­í•         | ì‘ì—…ì— ëŒ€í•œ ìŠ¤ì¼€ì¤„ë§            | ì‹¤ì§ˆì ì¸ ì—°ì‚°ì„ ë‹´ë‹¹             |
| RDD ìƒì„±              | ì‘ì—… ë¶„                   | ì—°ì‚° ê²°ê³¼ë¥¼ Driver Program ì „ |
| Python, Java, Scala | Hadoop(Yarn), AWS(EMR) |                         |

> Worker NodeëŠ” Cacheë¥¼ ê³µìœ í•˜ë©´ì„œ ì‘ì—…ì˜ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆì–´ìš”.

## PySpark ì„¤ì¹˜í•˜ê¸°&#x20;

### A. Docker ê¸°ë°˜ Spark ì„¤ì¹˜í•˜ê¸°

> ì§„í–‰í•˜ê¸° ì•ì„œ, [Docker.com](https://www.docker.com)ì—ì„œ ìš´ì˜ì²´ì œì— ë§ëŠ” Dockerë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

ì•„ë˜ ì½”ë“œì™€ ê°™ì´ Dockerë¥¼ í†µí•´ Local rootì™€ Internal rootë¥¼ ì—°ê²°ì‹œí‚µë‹ˆë‹¤.

ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë°›ê²Œ ë˜ë©´ ì¤‘ê°„ì— ë§í¬ê°€ ë“±ì¥í•˜ëŠ”ë° ë§í¬ë¥¼ í†µí•´ Jupyterì—ì„œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

```docker
docker run -it --rm -p 8888:8888 -v /Users/Local:/home/jovyan/work jupyter/pyspark-notebook
```

#### A-1. JuypterNotebook ì•ˆìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ë²•

`ps` ë¥¼ í†µí•´ ì‹¤í–‰ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ í™•ì¸í•œ ë‹¤ìŒ, ì»¨í…Œì´ë„ˆì˜ IDë¥¼ í†µí•´ ë“¤ì–´ê°€ì‹œë©´ ë©ë‹ˆë‹¤.

```
docker ps 
docker exec -it {CONTAINER ID} /bin/bash
```

#### A-2. Local <-> Docker íŒŒì¼ ë³µì‚¬í•˜ëŠ” ë²•

* Local -> Docker

```
docker cp {local pwd}/. {CONTAINER ID}:/home/jovyan/work
```

* Docker -> Local

```
docker cp {CONTAINER ID}:/home/jovyan/work {local pwd}
```

### B. DataBricks ì»¤ë®¤ë‹ˆí‹° ì—ë””ì…˜ì„ í†µí•´ ìŠ¤íŒŒí¬ ì‹¤í–‰

[https://www.databricks.com](https://www.databricks.com) ì‚¬ì´íŠ¸ë¥¼ ì´ìš©í•˜ì—¬ ì›¹ì„ í†µí•´ Noteë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>









